{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Install and import all the needed dependencies\n",
    "\n",
    "You need to start by installing three packages: mediapipe, opencv and scikit.\n",
    "\n",
    "NOTE: Once you have run this first block once you will not need to run it again.\n",
    "This just installs these packages onto your local machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe==0.10.9 opencv-python scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0)  Make some detections "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this if you want to make sure you have dependencies installed correctly.\n",
    "\n",
    "<!-- Hand Landmark Image Map <img src=\"https://i.imgur.com/8bForKY.png\">-->\n",
    "POSE GESTURE LANDMARKS GUIDE\n",
    "<img src=\"https://i.imgur.com/AzKNp7A.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp #Imports mediapipe\n",
    "import cv2 #Imports open cv\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False #precents copying data but still allows use of image for rendering\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "                \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True #precents copying data but still allows use of image for rendering\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Right hand - Draw the right hand keypoints\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 2. Left Hand - Draw the left hand keypoints\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Pose Detections - Draw the body keypoints as pictured below\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) CAPTURE LANDMARK DATA FOR A POSE AND SAVE IT TO A SPREADSHEET\n",
    "\n",
    "This creates a spreadsheet with a number of columns equal to the number of keypoints in your pose (33 total - it ignores the hands and face in the holistic model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Button 1 - CREATE SPREADSHEET\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "num_coords = len(results.pose_landmarks.landmark)\n",
    "num_coords\n",
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val),'y{}'.format(val),'z{}'.format(val),'v{}'.format(val)]\n",
    "with open('data.csv', mode='w',newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',',quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Button 2 - SET POSE NAME\n",
    "class_name = input(\"Enter the name for the pose : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Button 3 - COLLECT POSE DATA\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "num_coords = len(results.pose_landmarks.landmark)\n",
    "num_coords\n",
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val),'y{}'.format(val),'z{}'.format(val),'v{}'.format(val)]\n",
    "with open('data.csv', mode='w',newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',',quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)\n",
    "    \n",
    "class_name = input(\"Enter the name for the pose : \")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False #prevents copying data but still allows use of image for rendering\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)        \n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw the Right hand - Purely for show. The model doesn't use these in fitting an ML model\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 2. Draw the Left Hand - Purely for show. The model doesn't use these in fitting an ML model\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Pose Detections - This is where the magic is! These are the points you'll use\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "                        \n",
    "        # Export coordinates\n",
    "        try:\n",
    "            #Extract pose and face landmarks and put into numpy arrays\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            #print(pose_row) #Uncomment to output the poserow data to the screen\n",
    "\n",
    "            #concatenate rows\n",
    "            row = pose_row\n",
    "            \n",
    "            #append the class name to the row in the zeroth column\n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            #export to csv\n",
    "            with open('data.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row)\n",
    "            \n",
    "        except:\n",
    "            print(\"NERP MAGERP\")\n",
    "            pass\n",
    "        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) READ SPREADSHEET INTO A DATAFRAME\n",
    "\n",
    "Takes the spreadsheet from section 1 and reads it into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z31</th>\n",
       "      <th>v31</th>\n",
       "      <th>x32</th>\n",
       "      <th>y32</th>\n",
       "      <th>z32</th>\n",
       "      <th>v32</th>\n",
       "      <th>x33</th>\n",
       "      <th>y33</th>\n",
       "      <th>z33</th>\n",
       "      <th>v33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>Right Tandem</td>\n",
       "      <td>0.400500</td>\n",
       "      <td>0.247072</td>\n",
       "      <td>0.706913</td>\n",
       "      <td>0.997826</td>\n",
       "      <td>0.391777</td>\n",
       "      <td>0.246111</td>\n",
       "      <td>0.754640</td>\n",
       "      <td>0.994349</td>\n",
       "      <td>0.386644</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.394353</td>\n",
       "      <td>0.440951</td>\n",
       "      <td>0.388914</td>\n",
       "      <td>0.604618</td>\n",
       "      <td>-1.607975</td>\n",
       "      <td>0.399085</td>\n",
       "      <td>0.658242</td>\n",
       "      <td>0.610542</td>\n",
       "      <td>-1.629802</td>\n",
       "      <td>0.411492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>Right Tandem</td>\n",
       "      <td>0.416785</td>\n",
       "      <td>0.202730</td>\n",
       "      <td>-1.035553</td>\n",
       "      <td>0.997976</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>0.159012</td>\n",
       "      <td>-1.065934</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>0.408643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642470</td>\n",
       "      <td>0.422563</td>\n",
       "      <td>0.565718</td>\n",
       "      <td>0.604398</td>\n",
       "      <td>0.502094</td>\n",
       "      <td>0.418193</td>\n",
       "      <td>0.580037</td>\n",
       "      <td>0.604433</td>\n",
       "      <td>0.480790</td>\n",
       "      <td>0.418706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>Right Tandem</td>\n",
       "      <td>0.701842</td>\n",
       "      <td>0.504487</td>\n",
       "      <td>-0.151704</td>\n",
       "      <td>0.997313</td>\n",
       "      <td>0.697802</td>\n",
       "      <td>0.530398</td>\n",
       "      <td>-0.169159</td>\n",
       "      <td>0.994737</td>\n",
       "      <td>0.694386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377917</td>\n",
       "      <td>0.391942</td>\n",
       "      <td>0.556934</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>0.278288</td>\n",
       "      <td>0.385345</td>\n",
       "      <td>0.516009</td>\n",
       "      <td>-0.020136</td>\n",
       "      <td>0.381343</td>\n",
       "      <td>0.381730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>Right Tandem</td>\n",
       "      <td>0.466610</td>\n",
       "      <td>0.378551</td>\n",
       "      <td>0.214004</td>\n",
       "      <td>0.987408</td>\n",
       "      <td>0.476638</td>\n",
       "      <td>0.377616</td>\n",
       "      <td>0.202578</td>\n",
       "      <td>0.980648</td>\n",
       "      <td>0.478699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069763</td>\n",
       "      <td>0.426605</td>\n",
       "      <td>0.625711</td>\n",
       "      <td>0.377789</td>\n",
       "      <td>0.197643</td>\n",
       "      <td>0.363624</td>\n",
       "      <td>0.601898</td>\n",
       "      <td>0.339870</td>\n",
       "      <td>0.083818</td>\n",
       "      <td>0.377703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6310</th>\n",
       "      <td>Right Tandem</td>\n",
       "      <td>0.562592</td>\n",
       "      <td>0.587223</td>\n",
       "      <td>0.641245</td>\n",
       "      <td>0.982282</td>\n",
       "      <td>0.566940</td>\n",
       "      <td>0.593824</td>\n",
       "      <td>0.636792</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>0.569268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282563</td>\n",
       "      <td>0.478619</td>\n",
       "      <td>0.535416</td>\n",
       "      <td>0.075285</td>\n",
       "      <td>-0.200769</td>\n",
       "      <td>0.395817</td>\n",
       "      <td>0.551226</td>\n",
       "      <td>0.039313</td>\n",
       "      <td>-0.273036</td>\n",
       "      <td>0.414886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             class        x1        y1        z1        v1        x2  \\\n",
       "6306  Right Tandem  0.400500  0.247072  0.706913  0.997826  0.391777   \n",
       "6307  Right Tandem  0.416785  0.202730 -1.035553  0.997976  0.421214   \n",
       "6308  Right Tandem  0.701842  0.504487 -0.151704  0.997313  0.697802   \n",
       "6309  Right Tandem  0.466610  0.378551  0.214004  0.987408  0.476638   \n",
       "6310  Right Tandem  0.562592  0.587223  0.641245  0.982282  0.566940   \n",
       "\n",
       "            y2        z2        v2        x3  ...       z31       v31  \\\n",
       "6306  0.246111  0.754640  0.994349  0.386644  ... -1.394353  0.440951   \n",
       "6307  0.159012 -1.065934  0.994844  0.408643  ...  0.642470  0.422563   \n",
       "6308  0.530398 -0.169159  0.994737  0.694386  ...  0.377917  0.391942   \n",
       "6309  0.377616  0.202578  0.980648  0.478699  ...  0.069763  0.426605   \n",
       "6310  0.593824  0.636792  0.977000  0.569268  ... -0.282563  0.478619   \n",
       "\n",
       "           x32       y32       z32       v32       x33       y33       z33  \\\n",
       "6306  0.388914  0.604618 -1.607975  0.399085  0.658242  0.610542 -1.629802   \n",
       "6307  0.565718  0.604398  0.502094  0.418193  0.580037  0.604433  0.480790   \n",
       "6308  0.556934  0.011496  0.278288  0.385345  0.516009 -0.020136  0.381343   \n",
       "6309  0.625711  0.377789  0.197643  0.363624  0.601898  0.339870  0.083818   \n",
       "6310  0.535416  0.075285 -0.200769  0.395817  0.551226  0.039313 -0.273036   \n",
       "\n",
       "           v33  \n",
       "6306  0.411492  \n",
       "6307  0.418706  \n",
       "6308  0.381730  \n",
       "6309  0.377703  \n",
       "6310  0.414886  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Button 4 - IMPORT DATA\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split # allows you to make a training partition and a testing partition with your data\n",
    "df = pd.read_csv('acsm.csv') # reads in your coords.csv file into a dataframe\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3 PCA components out of 6\n",
      "Selected PCA components indices: [0 1 2]\n",
      "Data preprocessing complete. Here's a preview of the processed data:\n",
      "             0         1         2        class\n",
      "9745 -4.044725  1.621444  1.900983  Left Single\n",
      "9746  2.725031  3.366933  2.321481  Left Single\n",
      "9747 -3.740199  1.123429  1.769508  Left Single\n",
      "9748  2.571298  3.248768  2.752696  Left Single\n",
      "9749 -3.504421  0.051509  1.052343  Left Single\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import joblib\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "def augment_data_advanced(df, feature_names, augmentation_factor=0.1):\n",
    "    augmented_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        augmented_row = row.copy()\n",
    "        for feature in feature_names:\n",
    "            if np.random.rand() < 0.5:\n",
    "                augmented_row[feature] *= (1 + np.random.uniform(-augmentation_factor, augmentation_factor))\n",
    "        augmented_data.append(augmented_row)\n",
    "    return pd.DataFrame(augmented_data)\n",
    "\n",
    "# Load your dataframe\n",
    "# df = pd.read_csv('your_data.csv')  # Uncomment if reading from a CSV\n",
    "\n",
    "# Define feature names for keypoints 25 to 32\n",
    "selected_keypoints = [f'{axis}{i}' for i in range(25, 33) for axis in ['x', 'y', 'z', 'v']]\n",
    "\n",
    "# Check for missing values and drop rows with any missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Normalize the keypoint data\n",
    "scaler = StandardScaler()\n",
    "df[selected_keypoints] = scaler.fit_transform(df[selected_keypoints])\n",
    "\n",
    "# Save the scaler for use on live data\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "\n",
    "# Calculate z-scores for the features with a more conservative threshold\n",
    "z_scores = np.abs(stats.zscore(df[selected_keypoints]))\n",
    "threshold = 3.5  # More conservative threshold\n",
    "\n",
    "# Filter out the rows with any z-score greater than the threshold\n",
    "df = df[(z_scores < threshold).all(axis=1)]\n",
    "\n",
    "# Ensure all classes are represented\n",
    "class_counts = df['class'].value_counts()\n",
    "min_count = class_counts.min()\n",
    "df_balanced = pd.concat([resample(df[df['class'] == cls], replace=True, n_samples=min_count, random_state=123) for cls in class_counts.index])\n",
    "\n",
    "# Augment the data\n",
    "df_augmented = augment_data_advanced(df_balanced, selected_keypoints)\n",
    "df = pd.concat([df_balanced, df_augmented], ignore_index=True)\n",
    "\n",
    "# Dimensionality reduction with PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "principal_components = pca.fit_transform(df[selected_keypoints])\n",
    "\n",
    "# Save PCA for later use\n",
    "joblib.dump(pca, 'pca.joblib')\n",
    "\n",
    "df_pca = pd.DataFrame(data=principal_components)\n",
    "df_pca['class'] = df['class'].values\n",
    "\n",
    "# Feature selection\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "clf.fit(df_pca.iloc[:, :-1], df_pca['class'])\n",
    "\n",
    "selector = SelectFromModel(clf, prefit=True)\n",
    "selected_features_mask = selector.get_support()\n",
    "\n",
    "# Since PCA transforms the original features, we need to identify the selected PCA components\n",
    "pca_components_selected = np.where(selected_features_mask)[0]\n",
    "\n",
    "# Print the indices of the selected PCA components\n",
    "print(f\"Selected {pca_components_selected.shape[0]} PCA components out of {df_pca.shape[1] - 1}\")\n",
    "print(\"Selected PCA components indices:\", pca_components_selected)\n",
    "\n",
    "# Transform the PCA data to include only the selected features\n",
    "df_selected = pd.DataFrame(data=selector.transform(df_pca.iloc[:, :-1]))\n",
    "df_selected['class'] = df_pca['class'].values\n",
    "\n",
    "# Now your data is preprocessed and ready for modeling\n",
    "print(\"Data preprocessing complete. Here's a preview of the processed data:\")\n",
    "print(df_selected.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x25',\n",
       " 'y25',\n",
       " 'z25',\n",
       " 'v25',\n",
       " 'x26',\n",
       " 'y26',\n",
       " 'z26',\n",
       " 'v26',\n",
       " 'x27',\n",
       " 'y27',\n",
       " 'z27',\n",
       " 'v27',\n",
       " 'x28',\n",
       " 'y28',\n",
       " 'z28',\n",
       " 'v28',\n",
       " 'x29',\n",
       " 'y29',\n",
       " 'z29',\n",
       " 'v29',\n",
       " 'x30',\n",
       " 'y30',\n",
       " 'z30',\n",
       " 'v30',\n",
       " 'x31',\n",
       " 'y31',\n",
       " 'z31',\n",
       " 'v31',\n",
       " 'x32',\n",
       " 'y32',\n",
       " 'z32',\n",
       " 'v32']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) CREATE AN ML MODEL FOR LIVE CLASSIFICATION\n",
    "\n",
    "This will use the dataframe created in section 3 to generate multiple machine learning models (Logistic Regression, Ridge Regression, Random Forest and Gradient Descent). It will analyze these models and choose the best performing one and output into a file using JOBLIB for later use on live classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest CV Scores: 0.9963\n",
      "Default RandomForest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Double Leg       1.00      1.00      1.00       585\n",
      " Left Single       1.00      1.00      1.00       585\n",
      " Left Tandem       0.99      1.00      1.00       585\n",
      "Right Single       1.00      1.00      1.00       585\n",
      "Right Tandem       1.00      1.00      1.00       585\n",
      "\n",
      "    accuracy                           1.00      2925\n",
      "   macro avg       1.00      1.00      1.00      2925\n",
      "weighted avg       1.00      1.00      1.00      2925\n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best parameters found for RandomForest: {'bootstrap': False, 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 7, 'n_estimators': 154}\n",
      "Best cross-validation score for RandomForest: 0.9953\n",
      "Tuned RandomForest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Double Leg       1.00      1.00      1.00       585\n",
      " Left Single       1.00      1.00      1.00       585\n",
      " Left Tandem       0.99      1.00      1.00       585\n",
      "Right Single       1.00      1.00      1.00       585\n",
      "Right Tandem       1.00      1.00      1.00       585\n",
      "\n",
      "    accuracy                           1.00      2925\n",
      "   macro avg       1.00      1.00      1.00      2925\n",
      "weighted avg       1.00      1.00      1.00      2925\n",
      "\n",
      "Best tuned RandomForest model saved as 'best_tuned_rf_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define feature names for keypoints 25 to 32\n",
    "selected_keypoints = [f'{axis}{i}' for i in range(25, 33) for axis in ['x', 'y', 'z', 'v']]\n",
    "X = df_selected.iloc[:, :-1]\n",
    "y = df_selected['class']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234, stratify=y)\n",
    "\n",
    "# Cross-validation with default RandomForest\n",
    "rf_model = RandomForestClassifier(random_state=123)\n",
    "rf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5)\n",
    "print(f'RandomForest CV Scores: {rf_cv_scores.mean():.4f}')\n",
    "\n",
    "# Fit the model with the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the default RandomForest model\n",
    "print('Default RandomForest Classification Report:')\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# Hyperparameter tuning with RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 11),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(random_state=123), param_distributions=param_dist, n_iter=50, cv=5, random_state=123, n_jobs=-1, verbose=2)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from random search\n",
    "best_rf_model = random_search.best_estimator_\n",
    "rf_tuned_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "print(f'Best parameters found for RandomForest: {random_search.best_params_}')\n",
    "print(f'Best cross-validation score for RandomForest: {random_search.best_score_:.4f}')\n",
    "\n",
    "# Evaluate the tuned RandomForest model\n",
    "print('Tuned RandomForest Classification Report:')\n",
    "print(classification_report(y_test, rf_tuned_pred))\n",
    "\n",
    "# Save the best performing model\n",
    "joblib.dump(best_rf_model, 'best_tuned_rf_model.joblib')\n",
    "print(\"Best tuned RandomForest model saved as 'best_tuned_rf_model.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "      Double Leg Stance       1.00      1.00      1.00      1032\n",
      " Left Single Leg Stance       1.00      1.00      1.00       757\n",
      "     Left Tandem Stance       1.00      1.00      1.00      1028\n",
      "Right Single Leg Stance       1.00      1.00      1.00       879\n",
      "    Right Tandem Stance       1.00      1.00      1.00      1037\n",
      "\n",
      "               accuracy                           1.00      4733\n",
      "              macro avg       1.00      1.00      1.00      4733\n",
      "           weighted avg       1.00      1.00      1.00      4733\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1032    0    0    0    0]\n",
      " [   0  756    0    1    0]\n",
      " [   0    0 1028    0    0]\n",
      " [   0    0    0  879    0]\n",
      " [   0    0    0    0 1037]]\n",
      "Model saved as 'simplified_rf_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load your dataframe\n",
    "df = pd.read_csv('coords.csv')  # Replace with your actual file\n",
    "\n",
    "# Define feature names for keypoints 25 to 32\n",
    "selected_keypoints = [f'{axis}{i}' for i in range(25, 33) for axis in ['x', 'y', 'z', 'v']]\n",
    "selected_features = selected_keypoints + ['class']\n",
    "\n",
    "# Limit the DataFrame to the selected features\n",
    "df = df[selected_features]\n",
    "\n",
    "# Split the data\n",
    "X = df[selected_keypoints]\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234, stratify=y)\n",
    "\n",
    "# Train the RandomForest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(rf_model, 'simplified_rf_model.joblib')\n",
    "print(\"Model saved as 'simplified_rf_model.joblib'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) LIVE POSE CLASSIFICATION\n",
    "\n",
    "This will load the joblib model created above and apply it to a live camera feed for live classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717124300.569608       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M3 Pro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=161; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=118; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=185; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=6, min_samples_split=2, n_estimators=125; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=159; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=9, min_samples_split=3, n_estimators=62; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=9, min_samples_split=3, n_estimators=62; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=9, min_samples_split=3, n_estimators=136; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=56; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=7, min_samples_split=5, n_estimators=171; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=7, n_estimators=154; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=7, min_samples_split=3, n_estimators=166; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=7, min_samples_split=6, n_estimators=169; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=9, min_samples_split=9, n_estimators=126; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=9, n_estimators=63; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=147; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=188; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=5, min_samples_split=6, n_estimators=119; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=3, min_samples_split=6, n_estimators=53; total time=   0.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=8, min_samples_split=7, n_estimators=195; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=10, min_samples_split=6, n_estimators=199; total time=   0.7s\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tkinter import messagebox\n",
    "\n",
    "try:\n",
    "    # Load the saved model\n",
    "    model = joblib.load(\"simplified_rf_model.joblib\")\n",
    "\n",
    "    class_names = model.classes_\n",
    "\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose()\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # Define feature names for keypoints 25 to 32\n",
    "    selected_keypoints = [f'{axis}{i}' for i in range(25, 33) for axis in ['x', 'y', 'z', 'v']]\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frame_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            keypoints = []\n",
    "            for i in range(25, 33):\n",
    "                landmark = results.pose_landmarks.landmark[i]\n",
    "                keypoints.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "        else:\n",
    "            keypoints = [0] * len(selected_keypoints)\n",
    "\n",
    "        keypoints_df = pd.DataFrame([keypoints], columns=selected_keypoints)\n",
    "        \n",
    "        pose_probabilities = model.predict_proba(keypoints_df)[0]\n",
    "        threshold = 0.5\n",
    "\n",
    "        font_scale_detected = 1.5\n",
    "        font_thickness_detected = 2\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        x, y = 10, 50\n",
    "\n",
    "        detected_pose = np.argmax(pose_probabilities)\n",
    "        detected_prob = pose_probabilities[detected_pose]\n",
    "\n",
    "        if detected_prob >= threshold:\n",
    "            detected_text = f'Detected Pose: {class_names[detected_pose]} ({detected_prob:.2f})'\n",
    "        else:\n",
    "            detected_text = 'No pose detected'\n",
    "\n",
    "        (text_width, text_height), baseline = cv2.getTextSize(detected_text, font, font_scale_detected, font_thickness_detected)\n",
    "        rect_x1, rect_y1 = x, y - text_height - baseline\n",
    "        rect_x2, rect_y2 = x + text_width, y + baseline\n",
    "        cv2.rectangle(frame, (rect_x1, rect_y1), (rect_x2, rect_y2), (0, 0, 0), cv2.FILLED)\n",
    "        cv2.putText(frame, detected_text, (x, y), font, font_scale_detected, (255, 255, 255), font_thickness_detected, cv2.LINE_AA)\n",
    "\n",
    "        # Prepare text for each class\n",
    "        font_scale_table = 1\n",
    "        font_thickness_table = 2\n",
    "        table_start_y = y + text_height + 20  # Start position for the table\n",
    "        line_height = 40  # Height between each line\n",
    "\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            prob = pose_probabilities[i]\n",
    "            text = f'{class_name}: {prob:.0%}'\n",
    "\n",
    "            # Draw background rectangle for text\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale_table, font_thickness_table)\n",
    "            rect_x1, rect_y1 = x, table_start_y + i * line_height - text_height - baseline\n",
    "            rect_x2, rect_y2 = x + text_width, table_start_y + i * line_height + baseline\n",
    "            cv2.rectangle(frame, (rect_x1, rect_y1), (rect_x2, rect_y2), (0, 0, 0), cv2.FILLED)\n",
    "\n",
    "            # Display text\n",
    "            cv2.putText(frame, text, (x, table_start_y + i * line_height), font, font_scale_table, (255, 255, 255), font_thickness_table, cv2.LINE_AA)\n",
    "\n",
    "        # Draw the pose landmarks on the frame\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Pose Recognition', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "except Exception as e:\n",
    "    messagebox.showerror(\"Error\", f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718749625.417666       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M3 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import joblib\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class PoseApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Pose Recognition GUI\")\n",
    "\n",
    "        # Button 1 - CREATE SPREADSHEET\n",
    "        self.button1 = tk.Button(root, text=\"CREATE SPREADSHEET\", command=self.create_spreadsheet)\n",
    "        self.button1.pack(pady=10)\n",
    "\n",
    "        # Button 2 - SET POSE NAME\n",
    "        self.button2 = tk.Button(root, text=\"SET POSE NAME\", command=self.set_pose_name)\n",
    "        self.button2.pack(pady=10)\n",
    "\n",
    "        # Button 3 - COLLECT POSE DATA\n",
    "        self.button3 = tk.Button(root, text=\"COLLECT POSE DATA\", command=self.collect_pose_data)\n",
    "        self.button3.pack(pady=10)\n",
    "\n",
    "        # Button 4 - IMPORT DATA\n",
    "        self.button4 = tk.Button(root, text=\"IMPORT DATA\", command=self.import_data)\n",
    "        self.button4.pack(pady=10)\n",
    "\n",
    "        # Button 5 - CREATE A MODEL!\n",
    "        self.button5 = tk.Button(root, text=\"CREATE A MODEL!\", command=self.create_model)\n",
    "        self.button5.pack(pady=10)\n",
    "\n",
    "        # Button 6 - LIVE CLASSIFY!\n",
    "        self.button6 = tk.Button(root, text=\"LIVE CLASSIFY!\", command=self.live_classify)\n",
    "        self.button6.pack(pady=10)\n",
    "        \n",
    "        self.pose_name = \"\"\n",
    "        self.df = None\n",
    "\n",
    "    def create_spreadsheet(self):\n",
    "        try:\n",
    "            num_coords = 33  # Assuming 33 landmarks, replace with the correct number if needed\n",
    "            landmarks = ['class']\n",
    "            for val in range(1, num_coords + 1):\n",
    "                landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "            with open('data.csv', mode='w', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(landmarks)\n",
    "            messagebox.showinfo(\"Success\", \"Spreadsheet created successfully!\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {e}\")\n",
    "\n",
    "    def set_pose_name(self):\n",
    "        self.pose_name = simpledialog.askstring(\"Input\", \"Enter the name for the pose:\")\n",
    "        if self.pose_name:\n",
    "            messagebox.showinfo(\"Success\", f\"Pose name set to: {self.pose_name}\")\n",
    "\n",
    "    def collect_pose_data(self):\n",
    "        if not self.pose_name:\n",
    "            messagebox.showerror(\"Error\", \"Please set the pose name first!\")\n",
    "            return\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        mp_holistic = mp.solutions.holistic\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "                results = holistic.process(image)\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "                mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "\n",
    "                try:\n",
    "                    pose = results.pose_landmarks.landmark\n",
    "                    pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "                    row = pose_row\n",
    "                    row.insert(0, self.pose_name)\n",
    "\n",
    "                    with open('data.csv', mode='a', newline='') as f:\n",
    "                        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        csv_writer.writerow(row)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                cv2.imshow('Raw Webcam Feed', image)\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def import_data(self):\n",
    "        try:\n",
    "            self.df = pd.read_csv('coords.csv')\n",
    "            messagebox.showinfo(\"Success\", \"Data imported successfully!\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {e}\")\n",
    "\n",
    "    def create_model(self):\n",
    "        if self.df is None:\n",
    "            messagebox.showerror(\"Error\", \"Please import the data first!\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            print(\"Building ML model\")\n",
    "            feature_names = [f'keypoint_{i}_{axis}' for i in range(33) for axis in ['x', 'y', 'z', 'visibility']]\n",
    "            x = self.df.drop('class', axis=1)\n",
    "            x.columns = feature_names\n",
    "            y = self.df['class']\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1234, stratify=y)\n",
    "\n",
    "            models = {\n",
    "                'Logistic Regression': LogisticRegression(max_iter=10000),\n",
    "                'Ridge Classifier': RidgeClassifier(),\n",
    "                'Random Forest': RandomForestClassifier(random_state=1234),\n",
    "                'Gradient Boosting': GradientBoostingClassifier(random_state=1234)\n",
    "            }\n",
    "\n",
    "            pipelines = {name: make_pipeline(StandardScaler(), model) for name, model in models.items()}\n",
    "            cv_scores = {name: cross_val_score(pipeline, X_train, y_train, cv=5) for name, pipeline in pipelines.items()}\n",
    "            best_model_name = max(cv_scores, key=lambda name: cv_scores[name].mean())\n",
    "            best_model = pipelines[best_model_name]\n",
    "            best_model.fit(X_train, y_train)\n",
    "            y_pred = best_model.predict(X_test)\n",
    "\n",
    "            print('Classification Report:')\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            print('Confusion Matrix:')\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "            joblib_file_model = \"best_tuned_model.joblib\"\n",
    "            joblib.dump(best_model, joblib_file_model)\n",
    "            messagebox.showinfo(\"Success\", f\"Model created and saved as {joblib_file_model}!\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {e}\")\n",
    "\n",
    "    def live_classify(self):\n",
    "        try:\n",
    "            best_tuned_model = joblib.load(\"best_tuned_model.joblib\")\n",
    "\n",
    "            scaler = best_tuned_model.named_steps['standardscaler']\n",
    "            model = best_tuned_model.named_steps[best_tuned_model.steps[-1][0]]\n",
    "\n",
    "            class_names = model.classes_\n",
    "\n",
    "            mp_pose = mp.solutions.pose\n",
    "            pose = mp_pose.Pose()\n",
    "            mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "            feature_names = [f'keypoint_{i}_{axis}' for i in range(33) for axis in ['x', 'y', 'z', 'visibility']]\n",
    "\n",
    "            cap = cv2.VideoCapture(0)\n",
    "\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = pose.process(frame_rgb)\n",
    "\n",
    "                if results.pose_landmarks:\n",
    "                    keypoints = []\n",
    "                    for landmark in results.pose_landmarks.landmark:\n",
    "                        keypoints.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "                else:\n",
    "                    keypoints = [0] * len(feature_names)\n",
    "\n",
    "                keypoints_df = pd.DataFrame([keypoints], columns=feature_names)\n",
    "                keypoints_scaled = scaler.transform(keypoints_df)\n",
    "                pose_probabilities = model.predict_proba(keypoints_scaled)[0]\n",
    "                threshold = 0.5\n",
    "\n",
    "                font_scale_detected = 1.5\n",
    "                font_thickness_detected = 2\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                x, y = 10, 50\n",
    "\n",
    "                detected_pose = np.argmax(pose_probabilities)\n",
    "                detected_prob = pose_probabilities[detected_pose]\n",
    "\n",
    "                if detected_prob >= threshold:\n",
    "                    detected_text = f'Detected Pose: {class_names[detected_pose]} ({detected_prob:.2f})'\n",
    "                else:\n",
    "                    detected_text = 'No pose detected'\n",
    "\n",
    "                (text_width, text_height), baseline = cv2.getTextSize(detected_text, font, font_scale_detected, font_thickness_detected)\n",
    "                rect_x1, rect_y1 = x, y - text_height - baseline\n",
    "                rect_x2, rect_y2 = x + text_width, y + baseline\n",
    "                cv2.rectangle(frame, (rect_x1, rect_y1), (rect_x2, rect_y2), (0, 0, 0), cv2.FILLED)\n",
    "                cv2.putText(frame, detected_text, (x, y), font, font_scale_detected, (255, 255, 255), font_thickness_detected, cv2.LINE_AA)\n",
    "\n",
    "                # Prepare text for each class\n",
    "                font_scale_table = 1\n",
    "                font_thickness_table = 2\n",
    "                table_start_y = y + text_height + 20  # Start position for the table\n",
    "                line_height = 40  # Height between each line\n",
    "\n",
    "                for i, class_name in enumerate(class_names):\n",
    "                    prob = pose_probabilities[i]\n",
    "                    text = f'{class_name}: {prob:.0%}'\n",
    "\n",
    "                    # Draw background rectangle for text\n",
    "                    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale_table, font_thickness_table)\n",
    "                    rect_x1, rect_y1 = x, table_start_y + i * line_height - text_height - baseline\n",
    "                    rect_x2, rect_y2 = x + text_width, table_start_y + i * line_height + baseline\n",
    "                    cv2.rectangle(frame, (rect_x1, rect_y1), (rect_x2, rect_y2), (0, 0, 0), cv2.FILLED)\n",
    "\n",
    "                    # Display text\n",
    "                    cv2.putText(frame, text, (x, table_start_y + i * line_height), font, font_scale_table, (255, 255, 255), font_thickness_table, cv2.LINE_AA)\n",
    "\n",
    "                # Draw the pose landmarks on the frame\n",
    "                if results.pose_landmarks:\n",
    "                    mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "                # Display the frame\n",
    "                cv2.imshow('Pose Recognition', frame)\n",
    "    \n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "    \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {e}\")\n",
    "\n",
    "            \n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = PoseApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
